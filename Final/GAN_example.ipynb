{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1: # initialize for Conv layers\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02) # (mean=0.0, std=0.02)\n",
    "    elif classname.find('BatchNorm') != -1: # initialize for BatchNorm layers\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0) # set bias to 0\n",
    "           \n",
    "class CBR(nn.Sequential): # Convolution-BatchNorm-ReLU block\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n",
    "        \"\"\"\n",
    "        當 group 參數被設置為大於1的值時, 卷積操作將會被分成 group 個子組,\n",
    "        每個子組使用不同的卷積核進行卷積計算。這些子組的輸出將被串聯起來形成最終的卷積輸出\n",
    "        \"\"\"\n",
    "        padding = (kernel_size - 1) // 2 # make output size the same\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        super(CBR, self).__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            nn.ReLU(inplace=True), # inplace=True: 計算結果直接覆蓋輸入\n",
    "        )\n",
    "class CBLR(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        super(CBLR, self).__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "class TCBR(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=4, stride=2, padding=1):\n",
    "        \"\"\"\n",
    "        ConvTranspose2d: 轉置卷積層將輸入特徵圖進行放大(upsampling)\n",
    "        \"\"\"\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        super(TCBR, self).__init__(\n",
    "            nn.ConvTranspose2d(in_planes, out_planes, kernel_size, stride, padding, bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )                    \n",
    "                                                 \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latents):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layer1= nn.Sequential(\n",
    "            # input is random_Z,  state size. latents x 1 x 1 \n",
    "            # going into a convolution\n",
    "            TCBR(latents, 256, 4, 2, 1),  # state size. 256 x 2 x 2\n",
    "            CBR(256, 128, 3, 1)\n",
    "        )\n",
    "        \n",
    "        self.layer2= nn.Sequential(\n",
    "            TCBR(128, 256, 4, 1, 0), # state size. 256 x 3 x 3\n",
    "            TCBR(256, 256, 4, 2, 1), # state size. 256 x 6 x 6\n",
    "            \n",
    "        )\n",
    "        self.layer3= nn.Sequential(\n",
    "            TCBR(256, 128, 4, 1, 0), # state size. 256 x 7 x 7\n",
    "            TCBR(128, 128, 4, 2, 1),  # state size. 256 x 14 x 14\n",
    "            CBR(128, 128, 3, 1)\n",
    "            # state size. 256 x 6 x 6\n",
    "\n",
    "        )\n",
    "        self.layer4= nn.Sequential(\n",
    "            TCBR(128, 64, 4, 2, 1), # state size. 64 x 28 x 28\n",
    "            CBR(64, 64, 3, 1),\n",
    "            CBR(64, 64, 3, 1),\n",
    "            nn.Conv2d(64, 1, 3, 1, 1), # state size. 1 x 28 x 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            CBLR(1, 32, 3, 2), # b*32*14*14\n",
    "            CBLR(32, 64, 3, 1), # b*64*14*14\n",
    "            CBLR(64, 128, 3, 2), # b*128*7*7\n",
    "            CBLR(128, 128, 3, 2), # b*32*3*3\n",
    "            CBLR(128, 64, 3, 2), # b*32*1*1\n",
    "        )        \n",
    "        self.fc = nn.Linear(64,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, 1).reshape(x.shape[0], -1)\n",
    "        ft = x\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.utils import save_image\n",
    "\n",
    "flag_gpu = 1\n",
    "# Number of workers for dataloader\n",
    "workers = 0\n",
    "# Batch size during training\n",
    "batch_size = 100\n",
    "# Number of training epochs\n",
    "epochs = 20\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# GPU\n",
    "device = 'cuda:0' if (torch.cuda.is_available() & flag_gpu) else 'cpu'\n",
    "print('GPU State:', device)\n",
    "# Model\n",
    "latent_dim = 10\n",
    "G = Generator(latents=latent_dim).to(device)\n",
    "D = Discriminator().to(device)\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "# Settings\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "g_scheduler = torch.optim.lr_scheduler.StepLR(g_optimizer, step_size=5, gamma=0.5)\n",
    "d_scheduler = torch.optim.lr_scheduler.StepLR(d_optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# Load data\n",
    "train_set = datasets.MNIST('./', train=True, download=False, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, epoch):\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    plt.figure()\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(sqrtn, sqrtn, index+1)\n",
    "        plt.imshow(image.reshape(28, 28))\n",
    "    plt.savefig(\"Generator_epoch_{}.png\".format(epoch))\n",
    "# Train\n",
    "adversarial_loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "# adversarial_loss = torch.nn.BCELoss().to(device)\n",
    "\n",
    "G.train()\n",
    "D.train()\n",
    "loss_g, loss_d = [],[]\n",
    "start_time= time.time()\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    total_loss_g,total_loss_d=0,0\n",
    "    count_d=0\n",
    "    for i_iter, (images, label) in enumerate(train_loader):\n",
    "        i_iter += 1\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        g_optimizer.zero_grad()\n",
    "        # Sample noise as generator input\n",
    "        noise = torch.randn(images.shape[0], latent_dim, 1, 1)\n",
    "        noise = noise.to(device)\n",
    "        \n",
    "        # 因為Generator希望生成出來的圖片跟真的一樣，所以fake_label標註用 1\n",
    "        fake_label = torch.ones(images.shape[0], dtype=torch.long).to(device) # notice: label = 1\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_inputs = G(noise)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        loss_g_value = adversarial_loss(fake_outputs, fake_label)\n",
    "        loss_g_value.backward()\n",
    "        g_optimizer.step()\n",
    "        total_loss_g+=loss_g_value\n",
    "        loss_g.append(loss_g_value) \n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        # Zero the parameter gradients\n",
    "        d_optimizer.zero_grad()\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        # 因為Discriminator希望判斷哪些是真的那些是生成的，所以real_label資料標註用 1，fake_label標註用0。\n",
    "        real_inputs = images.to(device) \n",
    "        real_label = torch.ones(real_inputs.shape[0], dtype=torch.long).to(device)\n",
    "        fake_label = torch.zeros(fake_inputs.shape[0], dtype=torch.long).to(device)\n",
    "#       learning by Discriminator\n",
    "        real_loss = adversarial_loss(D(real_inputs),real_label)\n",
    "        fake_loss = adversarial_loss(D(fake_inputs.detach()),fake_label)\n",
    "        loss_d_value = (real_loss + fake_loss) / 2\n",
    "        loss_d_value.backward()\n",
    "        d_optimizer.step()\n",
    "        total_loss_d+=loss_d_value\n",
    "        loss_d.append(loss_d_value)  \n",
    "        \n",
    "    total_loss_g/=len(train_loader)\n",
    "    total_loss_d/=len(train_loader)         \n",
    "    g_scheduler.step()\n",
    "    d_scheduler.step()\n",
    "    print('[Epoch: {}/{}] D_loss: {:.3f} G_loss: {:.3f}'.format(epoch, epochs, total_loss_d.item(), total_loss_g.item()))\n",
    "    if epoch % 1 == 0:\n",
    "        print('Generated images for epoch: {}'.format(epoch))\n",
    "        imgs_numpy = fake_inputs.data.cpu().numpy()\n",
    "        show_images(imgs_numpy[:16],epoch)\n",
    "        plt.show()\n",
    "\n",
    "torch.save(G, 'DCGAN_Generator.pth')\n",
    "torch.save(D, 'DCGAN_Discriminator.pth')\n",
    "print('Model saved.')\n",
    "\n",
    "print('Training Finished.')\n",
    "print('Cost Time: {}s'.format(time.time()-start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
